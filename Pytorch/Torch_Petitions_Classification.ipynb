{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5ebee71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e06e418",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'result = pd.DataFrame()           \\n\\nfor i in range(584274, 595226):  # 595226\\n    URL = \"http://www1.president.go.kr/petitions/\"+str(i)\\n \\n    response = requests.get(URL)\\n    html = response.text                          \\n    soup = BeautifulSoup(html, \\'html.parser\\')           \\n\\n    title = soup.find(\\'h3\\', class_=\\'petitionsView_title\\')\\n    count = soup.find(\\'span\\', class_=\\'counter\\')           \\n\\n    for content in soup.select(\\'div.petitionsView_write > div.View_write\\'):\\n        content                                         \\n\\n    a=[]\\n    for tag in soup.select(\\'ul.petitionsView_info_list > li\\'): \\n        a.append(tag.contents[1])\\n\\n    if len(a) != 0:\\n        df1=pd.DataFrame({ \\'start\\' : [a[1]],                \\n                           \\'end\\' : [a[2]],                     \\n                           \\'category\\' :  [a[0]],               \\n                           \\'count\\' : [count.text],             \\n                           \\'title\\': [title.text],              \\n                           \\'content\\': [content.text.strip()[0:13000]]                              \\n                         })\\n\\n        result = pd.concat([result, df1])                        \\n        result.index = np.arange(len(result))             \\n\\n    if i % 60 == 0:                                        \\n        print(\"Sleep 90seconds. Count:\" + str(i)           \\n              +\",  Local Time:\"+ time.strftime(\\'%Y-%m-%d\\', time.localtime(time.time()))\\n              +\" \"+ time.strftime(\\'%X\\', time.localtime(time.time()))\\n              +\",  Data Length:\"+ str(len(result)))        \\n        time.sleep(90)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''result = pd.DataFrame()           \n",
    "\n",
    "for i in range(584274, 595226):  # 595226\n",
    "    URL = \"http://www1.president.go.kr/petitions/\"+str(i)\n",
    " \n",
    "    response = requests.get(URL)\n",
    "    html = response.text                          \n",
    "    soup = BeautifulSoup(html, 'html.parser')           \n",
    "\n",
    "    title = soup.find('h3', class_='petitionsView_title')\n",
    "    count = soup.find('span', class_='counter')           \n",
    "\n",
    "    for content in soup.select('div.petitionsView_write > div.View_write'):\n",
    "        content                                         \n",
    "\n",
    "    a=[]\n",
    "    for tag in soup.select('ul.petitionsView_info_list > li'): \n",
    "        a.append(tag.contents[1])\n",
    "\n",
    "    if len(a) != 0:\n",
    "        df1=pd.DataFrame({ 'start' : [a[1]],                \n",
    "                           'end' : [a[2]],                     \n",
    "                           'category' :  [a[0]],               \n",
    "                           'count' : [count.text],             \n",
    "                           'title': [title.text],              \n",
    "                           'content': [content.text.strip()[0:13000]]                              \n",
    "                         })\n",
    "\n",
    "        result = pd.concat([result, df1])                        \n",
    "        result.index = np.arange(len(result))             \n",
    "\n",
    "    if i % 60 == 0:                                        \n",
    "        print(\"Sleep 90seconds. Count:\" + str(i)           \n",
    "              +\",  Local Time:\"+ time.strftime('%Y-%m-%d', time.localtime(time.time()))\n",
    "              +\" \"+ time.strftime('%X', time.localtime(time.time()))\n",
    "              +\",  Data Length:\"+ str(len(result)))        \n",
    "        time.sleep(90)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10d7b8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(result.shape)\n",
    "\n",
    "# df = result\n",
    "# df.head()\n",
    "\n",
    "# df.to_csv('data/crawling.csv', index = False, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "524a5dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'보험업법에 약관에 명확하게 해석 되어지지 않을경우\\r\\n소비자가 유리한쪽으로 해석 한다고 명시 되어 있습니다\\n\\r\\n그런데 보험회사가 약관에도 없는 회사 규정을 만들어서 지급이 안된다는것도 아니고\\r\\n지금 까지 안준다고 하니깐 약관 갖고 와서 따지는 사람이 없어서 누구는 주고 누구는 줄수 없어서\\r\\n지금이 어려울거 같다는 말만 반복합니다\\n\\n\\r\\n2006년도에 들었던 성인특정질환통원치료시\\r\\n1회당 지급한다고 약관에 써 놓고\\r\\n가입시 약관에 회당 지급이라 병원 치료 받을때 마다 나오니깐 맘편히 아프면 병원 다닐수 있는 좋은 특약 이라고 가입 시켜 놓고\\r\\n당뇨 고혈압 협심증으로 3회 통원 하였으나 협심증 하나만\\r\\n약관에도 없는 회사 규정을 내세우면서\\r\\n같은날 같은병원에서 치료 받았다고 협심증하나만 지급 한다고 합니다\\n\\r\\n또한 백내장으로 통원 하여 오른쪽 왼쪽 같은날 같은병원에서 각각 다른 전문의에게 2회 통원치료 받았으나 한쪽눈은 진료비를 냈고 한쪽 눈은 무료진료에 검사비 촬영비만 냈고 무료 진료 라서 통원비 지급이 어렵다고 합니다\\r\\n하지만 약관에 통원에 정의는 치료가 필요하다고 인정된경우 의사의 관리하에 치료 하였을때라고 써 있지 진료비 납부 한거만 인정 한다고 써 있지도 않은 회사 규정을 내세우며 지급 하지 않고 있습니다\\r\\n타보험사도 통원비는 진료비와 상관없이 치료 받으면 지급 하고 있는데 약관에 없는 규정 까지 만들면서 지급 하지 않고 있습니다\\n\\n\\r\\n통원비는 1회당 지급 이라고 써 있고 약관에 다른 특별한 내용이 없어서 가입시 같은날 같은병원이라도 다른병이면 회당 모두 보상 된다는 뜻이라고 좋은보험 이라고 설명 듣고 가입 하였습니다\\n\\r\\n골절진단 자금을 보면 1회당 30만원지급한다고 써 있고 비고란에\\r\\n동일재해로 인한 2가지이상 골절 상태는 1회만 지급이라고 1회만 지급시에는 명확히 1회만 지급이라고 약관에 써 있으니깐 1회만 지급 하는게 맞지만\\n\\r\\n통원은 회당 지급 한다고만 써 있으니깐\\r\\n회당 지급 해달라고 하니깐 약관에 그렇게 써 있지만\\r\\n다른 고객들에게 거의 1회만 지급 했으므로 누구는 주고 누구는 안 줄수 없어 지급이 어려울거 같다는 말만 되풀이합니다 안된다는 말도 아니고 어려울거 같다고만합니다\\n\\r\\n수술자금을 보면 동시에 두 종류이상의 수술을 받더라도 동일한 신체 부위가 아니면 각각의 수술자금을 지급 한다라고 써 있습니다\\r\\n그런데 보험회사에서는 동시에 수술하면 다른신체부위라도 하나만 보장 한다고 하였다가 약관 보여 주니깐\\r\\n약관 마다 달라서 헷갈렸다고 합니다\\n\\r\\n이렇게 공정하지도 전문성도 떨어지는 보험 회사 어떻게 해야 할까요??\\n\\r\\n위에 내용에 대한 답을 서면으로 달라고 하니깐  한.생명 에서는 손해사정사에 위임 해서  거기서  처리한 내용이니  그곳에서  받으라고  주지 않습니다 \\n\\r\\n보험 회사에 보험을 들었는데  왜 보험 회사 고객센터에서  답변에 대한 서면을 못 받고 개인 손해 사정사 한테 받아야 하냐고 달라고 하니깐 보험 회사 고객센터직원분들은  나는 모른다 알아서 해라식으로 불친절합니다\\n\\r\\n약관에도 없는 회사 규정 만들어서 안 줄거면 약관은 왜 만들었는지 어이가 없습니다 \\r\\n약관대로 보험금을 받을수 있게 도와주세요  부탁드립니다'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/crawling.csv')\n",
    "\n",
    "df.loc[1]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f12380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_white_space(text):\n",
    "    text = re.sub(r'[\\t\\r\\n\\f\\v]', ' ', str(text))\n",
    "    return text\n",
    "\n",
    "def remove_special_char(text):\n",
    "    text = re.sub('[^ ㄱ-ㅣ가-힣 0-9]+', ' ', str(text))\n",
    "    return text\n",
    "\n",
    "df.title = df.title.apply(remove_white_space)\n",
    "df.title = df.title.apply(remove_special_char)\n",
    "\n",
    "df.content = df.content.apply(remove_white_space)\n",
    "df.content = df.content.apply(remove_special_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0f13f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'보험업법에 약관에 명확하게 해석 되어지지 않을경우  소비자가 유리한쪽으로 해석 한다고 명시 되어 있습니다   그런데 보험회사가 약관에도 없는 회사 규정을 만들어서 지급이 안된다는것도 아니고  지금 까지 안준다고 하니깐 약관 갖고 와서 따지는 사람이 없어서 누구는 주고 누구는 줄수 없어서  지금이 어려울거 같다는 말만 반복합니다    2006년도에 들었던 성인특정질환통원치료시  1회당 지급한다고 약관에 써 놓고  가입시 약관에 회당 지급이라 병원 치료 받을때 마다 나오니깐 맘편히 아프면 병원 다닐수 있는 좋은 특약 이라고 가입 시켜 놓고  당뇨 고혈압 협심증으로 3회 통원 하였으나 협심증 하나만  약관에도 없는 회사 규정을 내세우면서  같은날 같은병원에서 치료 받았다고 협심증하나만 지급 한다고 합니다   또한 백내장으로 통원 하여 오른쪽 왼쪽 같은날 같은병원에서 각각 다른 전문의에게 2회 통원치료 받았으나 한쪽눈은 진료비를 냈고 한쪽 눈은 무료진료에 검사비 촬영비만 냈고 무료 진료 라서 통원비 지급이 어렵다고 합니다  하지만 약관에 통원에 정의는 치료가 필요하다고 인정된경우 의사의 관리하에 치료 하였을때라고 써 있지 진료비 납부 한거만 인정 한다고 써 있지도 않은 회사 규정을 내세우며 지급 하지 않고 있습니다  타보험사도 통원비는 진료비와 상관없이 치료 받으면 지급 하고 있는데 약관에 없는 규정 까지 만들면서 지급 하지 않고 있습니다    통원비는 1회당 지급 이라고 써 있고 약관에 다른 특별한 내용이 없어서 가입시 같은날 같은병원이라도 다른병이면 회당 모두 보상 된다는 뜻이라고 좋은보험 이라고 설명 듣고 가입 하였습니다   골절진단 자금을 보면 1회당 30만원지급한다고 써 있고 비고란에  동일재해로 인한 2가지이상 골절 상태는 1회만 지급이라고 1회만 지급시에는 명확히 1회만 지급이라고 약관에 써 있으니깐 1회만 지급 하는게 맞지만   통원은 회당 지급 한다고만 써 있으니깐  회당 지급 해달라고 하니깐 약관에 그렇게 써 있지만  다른 고객들에게 거의 1회만 지급 했으므로 누구는 주고 누구는 안 줄수 없어 지급이 어려울거 같다는 말만 되풀이합니다 안된다는 말도 아니고 어려울거 같다고만합니다   수술자금을 보면 동시에 두 종류이상의 수술을 받더라도 동일한 신체 부위가 아니면 각각의 수술자금을 지급 한다라고 써 있습니다  그런데 보험회사에서는 동시에 수술하면 다른신체부위라도 하나만 보장 한다고 하였다가 약관 보여 주니깐  약관 마다 달라서 헷갈렸다고 합니다   이렇게 공정하지도 전문성도 떨어지는 보험 회사 어떻게 해야 할까요    위에 내용에 대한 답을 서면으로 달라고 하니깐  한 생명 에서는 손해사정사에 위임 해서  거기서  처리한 내용이니  그곳에서  받으라고  주지 않습니다    보험 회사에 보험을 들었는데  왜 보험 회사 고객센터에서  답변에 대한 서면을 못 받고 개인 손해 사정사 한테 받아야 하냐고 달라고 하니깐 보험 회사 고객센터직원분들은  나는 모른다 알아서 해라식으로 불친절합니다   약관에도 없는 회사 규정 만들어서 안 줄거면 약관은 왜 만들었는지 어이가 없습니다   약관대로 보험금을 받을수 있게 도와주세요  부탁드립니다'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65779ae7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "df['title_token'] = df.title.apply(okt.morphs)\n",
    "df['content_token'] = df.content.apply(okt.nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "997c92ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start            object\n",
      "end              object\n",
      "category         object\n",
      "count             int64\n",
      "title            object\n",
      "content          object\n",
      "title_token      object\n",
      "content_token    object\n",
      "token_final      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['token_final'] = df.title_token + df.content_token\n",
    "\n",
    "df['count'] = df['count'].replace({',' : ''}, regex = True).apply(lambda x : int(x))\n",
    "\n",
    "print(df.dtypes)\n",
    "\n",
    "df['label'] = df['count'].apply(lambda x: 'Yes' if x>=1000 else 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2878e6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop = df[['token_final', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dd37b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop.head()\n",
    "    \n",
    "df_drop.to_csv('data/df_drop.csv', index = False, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "092436b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=28455, vector_size=100, alpha=0.025)\n",
      "[('음주', 0.9041165709495544), ('뺑소니', 0.8885794281959534), ('살인죄', 0.8764309883117676), ('무면허', 0.8762173652648926), ('살인자', 0.8601719737052917), ('가정폭력', 0.8561177253723145), ('형량', 0.8555580973625183), ('스토킹', 0.8498249650001526), ('무기징역', 0.836279571056366), ('살인', 0.835899293422699)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "embedding_model = Word2Vec(df_drop['token_final'], \n",
    "                           sg = 1, # skip-gram\n",
    "                           vector_size = 100, \n",
    "                           window = 2, \n",
    "                           min_count = 1, \n",
    "                           workers = 4\n",
    "                           )\n",
    "\n",
    "print(embedding_model)\n",
    "\n",
    "model_result = embedding_model.wv.most_similar(\"음주운전\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33f93934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('음주', 0.9041165709495544), ('뺑소니', 0.8885794281959534), ('살인죄', 0.8764309883117676), ('무면허', 0.8762173652648926), ('살인자', 0.8601719737052917), ('가정폭력', 0.8561177253723145), ('형량', 0.8555580973625183), ('스토킹', 0.8498249650001526), ('무기징역', 0.836279571056366), ('살인', 0.835899293422699)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "embedding_model.wv.save_word2vec_format('data/petitions_tokens_w2v') \n",
    "loaded_model = KeyedVectors.load_word2vec_format('data/petitions_tokens_w2v')\n",
    "\n",
    "model_result = loaded_model.most_similar(\"음주운전\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "204d73cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "\n",
    "rng = RandomState()\n",
    "\n",
    "tr = df_drop.sample(frac=0.8, random_state=rng)\n",
    "val = df_drop.loc[~df_drop.index.isin(tr.index)]\n",
    "\n",
    "tr.to_csv('data/train.csv', index=False, encoding='utf-8-sig')\n",
    "val.to_csv('data/validation.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dd78753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.legacy.data import Field\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('[\\[\\]\\']', '', str(text))\n",
    "    text = text.split(', ')\n",
    "    return text\n",
    "\n",
    "TEXT = Field(tokenize=tokenizer)\n",
    "LABEL = Field(sequential = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08e1d54b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ['교통사고', '로', '뇌출혈', '을', '당한', '피해자', '신분증', '명함', '소지', '의', '가족', '에게', '단', '한', '차례', '도', '담당', '조', '사관', '은', '연락', '을', '취하', '지', '않았습니다', '오빠', '사건', '당일', '출장', '차', '목포', '일', '직접', '운전', '모텔', '투숙', '사건', '발생', '시간', '약', '모텔', '사고', '를', '투숙', '전', '후', '카드', '사용', '내용', '것', '보아', '모텔', '잠깐', '쉬', '저녁', '식사', '길', '불과', '지점', '좌회전', '차량', '보행', '사고', '발생', '교통사고', '피해자', '뇌출혈', '의식', '상태', '지갑', '명함', '소지', '보호자', '연락', '취하', '과정', '사건', '지구대', '경찰서', '관', '그', '담당', '경찰서', '뇌출혈', '발생', '전혀', '의식', '피해자', '회사', '가족', '단', '번', '연락', '취한', '적', '담당', '사관', '비번', '조차', '전혀', '업무', '인수', '인계', '가족', '회사', '단', '차례', '연락', '골든타임', '뇌출혈', '환자', '지구대', '방서', '즉시', '긴급', '출동', '오빠', '병원', '이송', '최선', '주신', '점', '진심', '감사', '이', '은혜', '절대', '담당', '경찰관', '비번', '업무', '제대로', '확인', '가족', '연락', '시간', '동안', '오빠', '혼자', '사고', '의식', '사경', '시간', '그', '담당', '사관', '비번', '때', '더', '장시간', '피해자', '가족', '몇', '날', '며칠', '더', '경과', '저', '이', '담당', '경찰관', '책임', '이', '사건', '다른', '경찰관', '이', '사건', '관', '피해자', '가족', '향', '사과', '말', '한마디', '큰소리', '팀', '장님', '사과', '직접', '누구', '실수', '수', '우리', '오빠', '상황', '발생', '또', '대처', '생각', '꼭', '업무', '메뉴얼', '번', '더', '확인', '점검', '이', '발생', '시오', '열흘', '지난', '지금', '오빠', '의식', '발생', '우리', '오빠', '수', '우리', '오빠', '년', '월', '일생', '부산', '회사', '품질', '부', '근무', '현재', '몸', '부모님', '생활', '책임', '집안', '가장', '사건', '당일', '오빠', '목포', '해양', '경찰청', '출장', '과', '목포', '호', '출장', '의', '품질', '관리', '위해', '목포', '금요일', '목', '금', '이틀', '오빠', '연락', '오빠', '출장', '중이', '회사', '측', '연락', '출장', '곳', '오빠', '출장', '오지', '연락', '소식', '평상시', '우리', '오빠', '성격', '연락', '출장', '가지', '사람', '바로', '회사', '연락', '취하', '오빠', '카드', '역', '숙박', '목포', '모텔', '향', '도중', '회사', '측', '사무실', '전화', '부재', '저녁', '추정', '지역', '번호', '오빠', '목포', '병원', '중환자실', '교통사고', '소식', '사고', '난', '하루', '뒤', '목포', '병원', '도착', '금', '오후', '추정', '하니', '오빠', '상태', '두개골', '골절', '외상', '막', '출혈', '양쪽', '팔다리', '곳', '하나', '의식', '채', '중환자실', '혼자', '병원', '중환자실', '간호사', '상황', '고', '차', '응급실', '를', '타고', '이송', '상황', '혼자', '사설', '구급차', '타고', '오빠', '광주', '대학병원', '응급실', '이송', '뒤', '중환자실', '오후', '사건', '담당', '지구대', '문의', '사건', '경찰서', '관', '목포', '경찰서', '연락', '경찰서', '대답', '담당', '경찰관', '비번', '사건', '내용', '알', '수가', '말', '부산', '가족', '오빠', '사고', '경위', '신분증', '명함', '소지', '오빠', '왜', '우리', '직접', '오빠', '병원', '중환자실', '의식', '상태', '알', '때', '왜', '가족', '회사', '측', '연락', '생각', '때문', '원통', '혼자', '보호자', '사경', '오빠', '생각', '가슴', '토요일', '다시', '한번', '오빠', '이', '사고', '경위', '연락', '것', '알', '토', '목포', '경찰서', '전화', '목', '저녁', '목포', '사고', '피해자', '가족', '오빠', '전혀', '의식', '중환자실', '사고', '경위', '알', '가족', '연락', '오지', '가족', '직접', '오빠', '상황', '알', '수가', '대답', '지금', '담당', '경찰관', '비번', '본인', '알', '수', '수', '그', '비번', '담당', '경찰관', '이', '상황', '전달', '달라', '비번', '사람', '몇', '시간', '동안', '근무', '퇴근', '수', '정말', '마음', '가지', '직접', '목포', '경찰서', '교통', '조사', '도착', '다시', '한번', '오빠', '상황', '전하', '가족', '상황', '알', '사관', '해당', '경찰관', '사건', '기록', '내용', '줄', '수', '블랙박스', '사건', '영상', '영상', '내용', '전남', '목포시', '평화로', '번길', '사거리', '오빠', '상대편', '차량', '좌회전', '오빠', '차량', '상황', '오빠', '바로', '뒤', '차량', '녹화', '보고', '오빠', '신분증', '회사', '명함', '소지', '왜', '가족', '회사', '연락', '담당', '경찰관', '알', '수', '대답', '제', '직접', '사건', '위해', '오빠', '숙박', '모텔', '사고', '지점', '불과', '도', '곳', '오빠', '숙박', '방', '기록', '목', '방', '모텔', '밖', '영상', '오빠', '사고', '난', '현장', '향', '영상', '사고', '현장', '출동', '지구대', '경찰관', '사건', '경위', '보호자', '연락', '취하', '오빠', '회사', '이름', '알', '연락', '퇴근', '연락', '담당', '사건', '경찰서', '관', '다음', '날', '경찰서', '연락', '생각', '소방', '서도', '사건', '당시', '출동', '소방관', '구급', '활동', '일지', '내용', '보고', '말씀', '신고', '일시', '병원', '도착', '시간', '환자', '의식', '보호자', '연락', '요구', '다시', '응급', '상황', '차', '오후', '병원', '보호자', '연락', '이야기', '다시', '지구대', '보호자', '연락', '요망', '전', '월요일', '오전', '처음', '담당', '사관', '전화', '바로', '목포', '경찰서', '경위', '사건', '담당자', '왜', '가족', '연락', '취하', '실수', '또한', '단', '한번', '회사', '가족', '연락', '시인', '월요일', '당시', '지구대', '수사', '내용', '이외', '가해자', '나본', '적도', '과정', '전혀', '그', '과정', '경찰서', '장님', '현재', '교통', '조사', '업무', '매뉴얼', '문제점', '사건', '발생', '의식', '불명', '사람', '신분증', '및', '명함', '소지', '비번', '이유', '가족', '연락', '상황', '꼭', '전달', '하니', '팀', '장님', '아주', '억압', '말투', '층', '청원', '감', '사실', '이야기', '청원', '감', '사실', '앞', '차례', '벨', '답', '상황', '다른', '분', '안', '문', '감', '사실', '두', '분', '상황', '장님', '이야기', '하니', '절차', '과장', '교통', '조사', '과장', '담당', '사관', '팀', '사관', '자신', '잘못', '팀', '분', '단', '번의', '사과', '저희', '향', '거', '뭐', '등', '억압', '분위기', '조성하', '말', '본인', '가족', '화', '낼', '수', '사과', '한마디', '조차', '수', '화가', '저희', '욕', '적도', '기물', '파손', '거나', '적도', '당장', '장님', '이', '부분', '점', '사과', '출장', '말', '과장', '명함', '주시', '이번', '주', '내', '시간', '연락', '말', '이틀', '동안', '교통', '조사', '과장', '연락', '제', '먼저', '연락', '하니', '대답', '이번', '장님', '휴가', '중이', '다음', '주', '시간', '답신', '온', '상태', '게시', '물의', '일부', '내용', '국민', '청원', '요건', '위배', '관리자', '수정'] Yes\n",
      "Validation: ['어린', '아이', '들', '을', '상대로', '허위', '사실', '을', '퍼뜨려', '수익', '을', '얻으려', '합니다', '게임', '학생', '사이', '인기', '이', '게임', '플레이', '유저', '이름', '유튜브', '운영', '유저', '위', '유튜버', '다른', '유저', '게임', '방해', '유튜브', '영상', '댓글', '사실', '글', '게시', '유저', '구독', '회수', '댓글', '본인', '수익', '타인', '허위', '사실', '유포', '본인', '이익', '조금', '생각', '사람', '라면', '법', '행위', '누구', '생각', '게임', '위', '유튜버', '어그', '성', '때문', '점검', '차례', '다른', '유저', '피해', '하루', '허위', '사실', '유포', '수익', '창', '출하', '려', '독자', '회수', '등', '유튜버', '계정', '삭제', '다른', '일', '일', '아이', '길', '청원', '게시', '물의', '일부', '내용', '국민', '청원', '요건', '위배', '관리자', '수정'] Yes\n"
     ]
    }
   ],
   "source": [
    "from torchtext.legacy.data import TabularDataset\n",
    "\n",
    "train, validation = TabularDataset.splits(\n",
    "    path = 'data/',\n",
    "    train = 'train.csv',\n",
    "    validation = 'validation.csv',\n",
    "    format = 'csv',\n",
    "    fields = [('text', TEXT), ('label', LABEL)],\n",
    "    skip_header = True\n",
    ")\n",
    "\n",
    "print(\"Train:\", train[0].text,  train[0].label)\n",
    "print(\"Validation:\", validation[0].text, validation[0].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5ae2b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 벡터의 개수와 차원 : torch.Size([26094, 100]) \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext.vocab import Vectors\n",
    "from torchtext.legacy.data import BucketIterator\n",
    "\n",
    "vectors = Vectors(name=\"data/petitions_tokens_w2v\")\n",
    "\n",
    "TEXT.build_vocab(train, vectors = vectors, min_freq = 1, max_size = None)\n",
    "LABEL.build_vocab(train)\n",
    "\n",
    "vocab = TEXT.vocab\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_iter, validation_iter = BucketIterator.splits(\n",
    "    datasets = (train, validation),\n",
    "    batch_size = 8,\n",
    "    device = device,\n",
    "    sort = False\n",
    ")\n",
    "\n",
    "print('임베딩 벡터의 개수와 차원 : {} '.format(TEXT.vocab.vectors.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b354109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn   \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class TextCNN(nn.Module): \n",
    "    \n",
    "    def __init__(self, vocab_built, emb_dim, dim_channel, kernel_wins, num_class):\n",
    "        \n",
    "        super(TextCNN, self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(len(vocab_built), emb_dim)\n",
    "        self.embed.weight.data.copy_(vocab_built.vectors)      \n",
    "    \n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, dim_channel, (w, emb_dim)) for w in kernel_wins])\n",
    "        self.relu = nn.ReLU()                \n",
    "        self.dropout = nn.Dropout(0.4)         \n",
    "        self.fc = nn.Linear(len(kernel_wins)*dim_channel, num_class)     \n",
    "        \n",
    "    def forward(self, x):  \n",
    "      \n",
    "        emb_x = self.embed(x)           \n",
    "        emb_x = emb_x.unsqueeze(1)  \n",
    "\n",
    "        con_x = [self.relu(conv(emb_x)) for conv in self.convs]       \n",
    "\n",
    "        pool_x = [F.max_pool1d(x.squeeze(-1), x.size()[2]) for x in con_x]    \n",
    "        \n",
    "        fc_x = torch.cat(pool_x, dim=1) \n",
    "        fc_x = fc_x.squeeze(-1)       \n",
    "        fc_x = self.dropout(fc_x)         \n",
    "\n",
    "        logit = self.fc(fc_x)     \n",
    "        \n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11b3f5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_itr, optimizer):\n",
    "    \n",
    "    model.train()                               \n",
    "    corrects, train_loss = 0.0,0        \n",
    "    \n",
    "    for batch in train_itr:\n",
    "        \n",
    "        text, target = batch.text, batch.label      \n",
    "        text = torch.transpose(text, 0, 1)          \n",
    "        target.data.sub_(1)                                 \n",
    "        text, target = text.to(device), target.to(device)  \n",
    "\n",
    "        optimizer.zero_grad()                           \n",
    "        logit = model(text)                         \n",
    "    \n",
    "        loss = F.cross_entropy(logit, target)   \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "        \n",
    "        train_loss += loss.item()    \n",
    "        result = torch.max(logit,1)[1] \n",
    "        corrects += (result.view(target.size()).data == target.data).sum()\n",
    "        \n",
    "    train_loss /= len(train_itr.dataset)\n",
    "    accuracy = 100.0 * corrects / len(train_itr.dataset)\n",
    "\n",
    "    return train_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46d64696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, device, itr):\n",
    "    \n",
    "    model.eval()\n",
    "    corrects, test_loss = 0.0, 0\n",
    "\n",
    "    for batch in itr:\n",
    "        \n",
    "        text = batch.text\n",
    "        target = batch.label\n",
    "        text = torch.transpose(text, 0, 1)\n",
    "        target.data.sub_(1)\n",
    "        text, target = text.to(device), target.to(device)\n",
    "        \n",
    "        logit = model(text)\n",
    "        loss = F.cross_entropy(logit, target)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        result = torch.max(logit,1)[1]\n",
    "        corrects += (result.view(target.size()).data == target.data).sum()\n",
    "\n",
    "    test_loss /= len(itr.dataset) \n",
    "    accuracy = 100.0 * corrects / len(itr.dataset)\n",
    "    \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c402785f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextCNN(\n",
      "  (embed): Embedding(26094, 100)\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(1, 10, kernel_size=(3, 100), stride=(1, 1))\n",
      "    (1): Conv2d(1, 10, kernel_size=(4, 100), stride=(1, 1))\n",
      "    (2): Conv2d(1, 10, kernel_size=(5, 100), stride=(1, 1))\n",
      "  )\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (fc): Linear(in_features=30, out_features=2, bias=True)\n",
      ")\n",
      "Train Epoch: 1 \t Loss: 0.08454519698797412 \t Accuracy: 58.616390228271484%\n",
      "Valid Epoch: 1 \t Loss: 0.08213517017792585 \t Accuracy: 59.97506332397461%\n",
      "model saves at 59.97506332397461 accuracy\n",
      "-----------------------------------------------------------------------------------\n",
      "Train Epoch: 2 \t Loss: 0.07929439885886 \t Accuracy: 64.00747680664062%\n",
      "Valid Epoch: 2 \t Loss: 0.0815988802107195 \t Accuracy: 62.344139099121094%\n",
      "model saves at 62.344139099121094 accuracy\n",
      "-----------------------------------------------------------------------------------\n",
      "Train Epoch: 3 \t Loss: 0.07147974867098575 \t Accuracy: 70.92552185058594%\n",
      "Valid Epoch: 3 \t Loss: 0.08059837347700115 \t Accuracy: 63.216957092285156%\n",
      "model saves at 63.216957092285156 accuracy\n",
      "-----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = TextCNN(vocab, 100, 10, [3, 4, 5], 2).to(device)\n",
    "print(model)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "best_test_acc = -1\n",
    "\n",
    "for epoch in range(1, 3+1):\n",
    " \n",
    "    tr_loss, tr_acc = train(model, device, train_iter, optimizer) \n",
    "    print('Train Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, tr_loss, tr_acc))\n",
    "    \n",
    "    val_loss, val_acc = evaluate(model, device, validation_iter)\n",
    "    print('Valid Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, val_loss, val_acc))\n",
    "        \n",
    "    if val_acc > best_test_acc:\n",
    "        best_test_acc = val_acc\n",
    "        \n",
    "        print(\"model saves at {} accuracy\".format(best_test_acc))\n",
    "        torch.save(model.state_dict(), \"TextCNN_Best_Validation\")\n",
    "    \n",
    "    print('-----------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ad309b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
